{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: make class vars instead of nested functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nibabel import freesurfer as fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,glob\n",
    "import re\n",
    "import cPickle as pkl\n",
    "from sklearn.feature_selection import variance_threshold\n",
    "from sklearn.utils import resample\n",
    "from joblib import Parallel,delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subject directory and subject list\n",
    "gitpath=os.getcwd()\n",
    "SUBJECTS_DIR=(\n",
    "    '/Volumes/Users/mbkranz/projects/'\n",
    "    'ACT_Freesurfer_NewProc/'\n",
    ")\n",
    "os.chdir(SUBJECTS_DIR)\n",
    "sublist=!ls -d ACT*_1\n",
    "os.chdir(gitpath)\n",
    "idx=pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import behavioral data or R prepped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npdatafilt=pd.read_csv(\n",
    "    '../data/np_filter_wb_gendernum.csv',\n",
    "    na_values='NA',\n",
    "    index_col=\"subs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg(X,Y):\n",
    "    n=len(X)\n",
    "    X = np.column_stack([np.ones(n),np.array(X)])\n",
    "    ## Uses the equation (X'X)^(-1)X'Y \n",
    "    #to calculate OLS coefficient estimates:\n",
    "    ##equivalent to the first element \n",
    "    #in the built in OLS fxn: np.linalg.lstsq\n",
    "    return np.dot(\n",
    "        np.linalg.inv(\n",
    "            np.dot(X.T,X)),\n",
    "        np.dot(X.T,Y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_regression(fs_np,y_np):\n",
    "    ifs_np,iy_np=resample(fs_np,y_np)\n",
    "    betas=linreg(iy_np,ifs_np)[1]\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not necessary to nest functions??\n",
    "#TO DO:\n",
    "#make loop _bootstrap an object\n",
    "#make run bootstrap as a fxn\n",
    "def bootstrap_mediation(fs_np,x_np,c_np,y_np):\n",
    "    #mediation based on \n",
    "    #Preacher and Hayes 2004\n",
    "    def pervertex_mediate():\n",
    "        def pervertex_regression():\n",
    "            #npdata=subject-wise data \n",
    "            #(e.g., age,cognitive scores)\n",
    "            #x_np,c_np,y_np=strings of npdata vars\n",
    "            iX=np.column_stack(\n",
    "                [ix_np,ic_np,icfs_np]\n",
    "            )\n",
    "            try:\n",
    "                betas=linreg(\n",
    "                    iX,iy_np\n",
    "                )\n",
    "            except:\n",
    "                betas=np.array(\n",
    "                    np.repeat(np.nan,iX.shape[1])\n",
    "                )\n",
    "            return betas\n",
    "        ###1 direct Y=i+cX\n",
    "        beta_c=linreg(\n",
    "            np.column_stack(\n",
    "                [ix_np,ic_np]\n",
    "            ),\n",
    "            iy_np)[1]\n",
    "        ###2 mediation (for each vertex) Y=i+c'X+bM\n",
    "        fs_iter=np.nditer(\n",
    "            ifs_np,flags=['external_loop'],\n",
    "            order='F'\n",
    "        )\n",
    "        beta_cprime=np.array(\n",
    "            [pervertex_regression()[1] \n",
    "             for icfs_np in fs_iter]\n",
    "        )\n",
    "        ###3 M=i+aX\n",
    "        #betas_m_a=linreg(npdata_df.filter([x,c]),fs_df)\n",
    "        #indirect effect=c minus c prime --> \n",
    "        #equivalent to -cprime+c --> \n",
    "        #equivalent to a*b \n",
    "        indirect=np.add(-beta_cprime,beta_c)\n",
    "        return indirect\n",
    "    ifs_np,ix_np,ic_np,iy_np=resample(\n",
    "        fs_np,x_np,c_np,y_np\n",
    "    )\n",
    "    test=pervertex_mediate()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "#make shorter fxns...\n",
    "#make loop _bootstrap an object\n",
    "#make run bootstrap as a fxn\n",
    "def loop_bootstrap(\n",
    "    np_name,\n",
    "    meas,\n",
    "    numsamples,\n",
    "    mediation=False,\n",
    "    x_name=None,\n",
    "    c_name=None,\n",
    "    y_name=None,\n",
    "    basedir=(SUBJECTS_DIR+\n",
    "            'ML_files/'),\n",
    "    fwhm=10\n",
    "):\n",
    "    def calc_bootstrap_summary():\n",
    "        #for each incoming sample x: \n",
    "        #(written with numpy functions for speed)\n",
    "            #if... first sample initiate values,\n",
    "        #else.... calculate running mean \n",
    "        #and standard deviation\n",
    "            #prev_mean = m;\n",
    "            #n = n + 1; (num_boot)\n",
    "            #m = m + (x-m)/n; (bootobj_mean)\n",
    "            #S = S + (x-m)*(x-prev_mean); (bootobj_q)\n",
    "        num_boot=0\n",
    "        for samplenum in xrange(numsamples):\n",
    "            num_boot+=1\n",
    "            if mediation==True:\n",
    "                bootobj=bootstrap_mediation(\n",
    "                    fsdatafilt.values,\n",
    "                    npdatafilt[x_name].values,\n",
    "                    npdatafilt[c_name].values,\n",
    "                    npdatafilt[y_name].values\n",
    "                )\n",
    "            else:\n",
    "                bootobj=bootstrap_regression(\n",
    "                    fsdatafilt.values,\n",
    "                    npdatafilt[np_name].values\n",
    "                )\n",
    "            if num_boot==1:\n",
    "                bootobj_mean=bootobj\n",
    "                bootobj_mean_minus1=np.zeros(\n",
    "                    len(fsdatafilt.columns)\n",
    "                )\n",
    "                bootobj_q=np.zeros(\n",
    "                    len(fsdatafilt.columns)\n",
    "                )\n",
    "            else:  \n",
    "                bootobj_prevmean=bootobj_mean.copy()\n",
    "                bootobj_mean=np.add(\n",
    "                    bootobj_mean,\n",
    "                    np.divide(\n",
    "                        np.subtract(\n",
    "                            bootobj,\n",
    "                            bootobj_mean\n",
    "                        ),\n",
    "                        num_boot\n",
    "                    )\n",
    "                )\n",
    "                bootobj_q=(\n",
    "                np.add(\n",
    "                    bootobj_q,\n",
    "                       np.multiply(\n",
    "                           np.subtract(\n",
    "                               bootobj,\n",
    "                               bootobj_mean),\n",
    "                           np.subtract(\n",
    "                               bootobj,\n",
    "                               bootobj_prevmean\n",
    "                           )\n",
    "                       )\n",
    "                      )\n",
    "                )\n",
    "        #final standard error estimate\n",
    "        bootobj_se=(\n",
    "            np.sqrt(\n",
    "                np.divide(\n",
    "                    bootobj_q,\n",
    "                    (num_boot-1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            '  3.)FINISHED bootstrap'\n",
    "            ' for x={},c={},y={}'\n",
    "            .format(x_name,c_name,y_name)\n",
    "        )\n",
    "        boot_df=pd.DataFrame({\n",
    "            'hemi_vertex':fsdatafilt.columns,\n",
    "            'bootse':bootobj_se,\n",
    "            'bootmean':bootobj_mean\n",
    "        })\n",
    "        return boot_df\n",
    "    netpath=(\n",
    "        '{}networks_ML/'\n",
    "        '{}_fwhm{}_wholebrainfsaverage_df.pkl'\n",
    "        .format(SUBJECTS_DIR,meas,str(fwhm))\n",
    "    )\n",
    "    fsdatafilt=pd.read_pickle(netpath)\n",
    "    if mediation==True:\n",
    "        print(\n",
    "            '  2.) Starting mediation bootstrap '\n",
    "            'for {} with x={},c={},y={}'\n",
    "            .format(meas,x_name,c_name,y_name)\n",
    "        )\n",
    "        pklfile=(\n",
    "            basedir+\n",
    "            'wholebrain_bootstrap_'\n",
    "            'vertex_mediation_'\n",
    "            '{}_{}_x{}_c{}_y{}_pd.pkl'\n",
    "            .format(np_name,\n",
    "                    meas,\n",
    "                    x_name,\n",
    "                    c_name,\n",
    "                    y_name)\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            '  2.) Starting regression bootstrap '\n",
    "            'for {} on {}\".format(meas,np_name)'\n",
    "        )\n",
    "        pklfile=(\n",
    "            basedir+\n",
    "            'wholebrain_bootstrap_'\n",
    "            'vertex_regression_'\n",
    "            '{}_{}_pd.pkl'\n",
    "            .format(np_name,meas)\n",
    "        )\n",
    "    bootstrap=calc_bootstrap_summary()\n",
    "    bootstrap['bootscore']=(\n",
    "        bootstrap['bootmean']/\n",
    "        bootstrap['bootse']\n",
    "    )\n",
    "    bootstrap.to_pickle(pklfile)\n",
    "    print(pklfile+'......SAVED!')\n",
    "    return pklfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measure_list=['area','thickness']\n",
    "np_name_list=['Memory','ExFunction']\n",
    "hemilist=['rh','lh']\n",
    "bootlist=['bootscore','bootmean']\n",
    "meas_key={'thickness':np.int(0),'area':np.int(1)}\n",
    "hemi_key={'lh':np.int(0),'rh':np.int(1)}\n",
    "n=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boot_df_mediation=Parallel(n_jobs=4)(\n",
    "    delayed(loop_bootstrap)(\n",
    "        np_name=np_name,\n",
    "        numsamples=n,\n",
    "        meas=meas,\n",
    "        x_name='Age',\n",
    "        c_name='Gender',\n",
    "        y_name=np_name,\n",
    "        mediation=True\n",
    "    ) \n",
    "    for meas in measure_list \n",
    "    for np_name in np_name_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np measure ~ morphometry regression\n",
    "boot_df=Parallel(n_jobs=4)(\n",
    "    delayed(loop_bootstrap)(\n",
    "        np_name=np_name,\n",
    "        numsamples=n,\n",
    "        meas=meas) \n",
    "    for meas in measure_list \n",
    "    for np_name in np_name_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getannot(annotname):\n",
    "    #initiate DataFrame\n",
    "    #may want to make concatenation/join \n",
    "    #(instead of append) \n",
    "    #so can have one column \n",
    "    #per annotation/set of labels\n",
    "    annot_df=[]\n",
    "    for hemi in hemilist:\n",
    "        annot_data=fs.read_annot(\n",
    "            '/Applications/freesurfer/'\n",
    "            'subjects/fsaverage/label/' + \n",
    "            hemi + \n",
    "            '.' + \n",
    "            annotname + \n",
    "            '.annot'\n",
    "        )\n",
    "        annot_hemi=pd.DataFrame({\n",
    "            \"annot_label\" : annot_data[0],\n",
    "            \"annot_name\": annotname, \n",
    "            \"vertex_index\" : range(\n",
    "                len(annot_data[0])\n",
    "            ), \n",
    "            \"hemi\": hemi_key[hemi]\n",
    "        })\n",
    "        annot_df.append(annot_hemi)\n",
    "    annots=(pd.concat(annot_df)\n",
    "            .set_index(['hemi','vertex_index'])\n",
    "           )\n",
    "    return annots\n",
    "def makesurf(np_name,meas,\n",
    "             mediation=False,\n",
    "             x_name=None,\n",
    "             c_name=None,\n",
    "             y_name=None,\n",
    "             basedir=(\n",
    "                 '../data/'\n",
    "                 'wholebrain_bootstrap/'\n",
    "             ),\n",
    "             curvdir='../curvoverlays/'):\n",
    "    if mediation==True:\n",
    "        pklfile=(\n",
    "            'wholebrain_bootstrap_'\n",
    "            'vertex_mediation_'\n",
    "            '{}_{}_x{}_c{}_y{}_pd.pkl'\n",
    "            .format(np_name,\n",
    "                    meas,\n",
    "                    x_name,\n",
    "                    c_name,\n",
    "                    y_name)\n",
    "                )\n",
    "    else:\n",
    "        pklfile=(\n",
    "            'wholebrain_bootstrap_'\n",
    "            'vertex_regression_'\n",
    "            '{}_{}_pd.pkl'\n",
    "            .format(np_name,meas)\n",
    "        )\n",
    "    #nptask=y target neuropsych variable to filter, \n",
    "    #filepath=path to save file to, \n",
    "    #measure=column vector name to save\n",
    "    #merge annotation labels \n",
    "    #(to allow re-sorting by hemi and then vertex index)\n",
    "    #get annotations from both hemis\n",
    "    #filter by hemisphere in the hemi_vertex strings, \n",
    "    #sort by hemi and vertex, extract values \n",
    "    #(labelled with integer col name 0)\n",
    "    df=pd.read_pickle(basedir+pklfile)\n",
    "    multi_i=pd.MultiIndex.from_tuples(\n",
    "        df['hemi_vertex'],\n",
    "        names=[0,'hemi','vertex_index']\n",
    "    ).droplevel([0])\n",
    "    del df['hemi_vertex']\n",
    "    df.index=multi_i\n",
    "    annots=getannot('Yeo2011_7Networks_N1000')\n",
    "    finaldf=df.join(annots,how='right').reset_index()\n",
    "    #write curv file for overlay \n",
    "    #for each hemi and bootstrap measure\n",
    "    for bootmeas in bootlist:\n",
    "        for hemi in hemilist:\n",
    "            hemi_index=hemi_key[hemi]\n",
    "            curv_vals=(\n",
    "                finaldf\n",
    "                .query('hemi==@hemi_index')\n",
    "                [bootmeas]\n",
    "                .values\n",
    "            )\n",
    "            file_path=(\n",
    "                pklfile\n",
    "                .replace(\n",
    "                    'pd.pkl','_'\n",
    "                    .join([bootmeas,hemi])+\n",
    "                    '.curv'\n",
    "                )\n",
    "            fs.write_morph_data(\n",
    "                file_like=curvdir+file_path,\n",
    "                values=curv_vals\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for np_name in np_name_list:\n",
    "    for measure in measure_list:\n",
    "        makesurf(\n",
    "            np_name,\n",
    "            measure,\n",
    "            mediation=True,\n",
    "            x_name='Age',\n",
    "            c_name='Gender',\n",
    "            y_name=np_name\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
