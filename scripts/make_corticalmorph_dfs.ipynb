{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO: test with code edits__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "- this notebook (1) concatenates preprocessed freesurfer data (i.e., resampled to fsaverage and smoothed for each subject), (2) adds annotation network labels (currently using the Yeo 7 Network annotation but can use any annotation file), and (3) filters by network and saves in pickle file\n",
    "- in a last part of this notebook, also loads the wholebrain fsaverage pickle file and calculates the wholebrain (ie., cortex) measures (surface area and thickness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#general packages used for data import etc\n",
    "from nibabel import freesurfer as fs\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,glob\n",
    "import re\n",
    "from joblib import Parallel,delayed\n",
    "import cPickle as pkl\n",
    "idx=pd.IndexSlice\n",
    "datapath=os.getwd().replace('scripts/','data/')\n",
    "#subject directory and subject list\n",
    "SUBJECTS_DIR=(\n",
    "    '/Volumes/Users/mbkranz/'\n",
    "    'projects/ACT_Freesurfer_NewProc/'\n",
    ")\n",
    "os.chdir(SUBJECTS_DIR)\n",
    "sublist=!ls -d ACT*_1\n",
    "#npdata from make_npdata_from_pca.R \n",
    "npdata_all=pd.read_csv(datapath+'np_all.csv',na_values='NA')\n",
    "#filter out all subs without behav data\n",
    "sublist_filt=[\n",
    "    x for x in sublist if int(re.sub(\"ACT0|ACT|_1\",\"\",x)) \n",
    "    in npdata_all['subs'].values and x!='ACT6142_1' #bad sub (see notes)\n",
    "]\n",
    "os.chdir(gitpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meas_key={'thickness':np.int(0),'area':np.int(1)}\n",
    "hemi_key={'lh':np.int(0),'rh':np.int(1)}\n",
    "net_key={'network'+str(net):net for net in [1,2,3,4,5,6,7]}\n",
    "net_key['wholebrain']=[1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getmorph(sub,measure,fwhm,hemi):\n",
    "    path_data=(\n",
    "        SUBJECTS_DIR+ sub+'/surf/'+\n",
    "        hemi+'.'+measure+'.'+'fwhm'+fwhm+\n",
    "        '.fsaverage.mgh'\n",
    "    )\n",
    "    morph_data=(nib.load(path_data)\n",
    "                .get_data()\n",
    "                .flatten())\n",
    "    morph_df=pd.DataFrame({\n",
    "        'subs':np.int(re.sub(\"ACT0|ACT|_1\",\"\",sub)),\n",
    "        'measure':meas_key[measure],\n",
    "        'hemi':hemi_key[hemi],\n",
    "        'value':morph_data})\n",
    "    return (morph_df\n",
    "            .rename_axis('vertex_index')\n",
    "            .set_index(['hemi'],append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getannot(annotname):\n",
    "    '''loads and concatenates annotation files for \n",
    "    both hemispheres and sets vertex and hemi ids\n",
    "    as indices (keys to join with subject wise metrics)\n",
    "    '''\n",
    "    hemilist=['lh','rh']\n",
    "    annot_df=[]\n",
    "    for hemi in hemilist:\n",
    "        annot_data=fs.read_annot(\n",
    "            '/Applications/freesurfer/'\n",
    "            'subjects/fsaverage/label/' +\n",
    "            hemi + '.' + annotname + '.annot'\n",
    "        )\n",
    "        annot_hemi=pd.DataFrame({\n",
    "            \"annot_label\" : annot_data[0],\n",
    "            \"hemi\": hemi_key[hemi]})\n",
    "        annot_df.append(annot_hemi)\n",
    "    annots=pd.concat(annot_df)\n",
    "    return (annots\n",
    "            .rename_axis('vertex_index')\n",
    "            .set_index(['hemi'],append=True)\n",
    "            .reorder_levels(['vertex_index','hemi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph_df_all=pd.concat(Parallel(n_jobs=4)(\n",
    "    delayed(getmorph)\n",
    "    (sub,meas,'10',hemi) \n",
    "    for sub in sublist_filt \n",
    "    for hemi in ['lh','rh']\n",
    "    for meas in ['thickness','area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annots=getannot('Yeo2011_7Networks_N1000')\n",
    "morph_df_annot=(\n",
    "    morph_df_all.join(annots)\n",
    "    .set_index(['subs','measure','annot_label'],append=True)\n",
    "    .reorder_levels(['annot_label',\n",
    "                     'measure',\n",
    "                     'hemi',\n",
    "                     'subs',\n",
    "                     'vertex_index'])\n",
    "    .sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_morph_data(meas,imeas,netname,inet):\n",
    "    '''takes the data loaded, combined, and joined with annotation file\n",
    "    across subs and (1) filters by network from annotation file and\n",
    "    (2) saves based on network filtered\n",
    "    '''\n",
    "    imorph_data=morph_df_annot.loc[idx[inet,imeas,:,:,:],:]\n",
    "    #drop as unstacking only hemi and vertex\n",
    "    imorph_data.index=imorph_data.index.droplevel('annot_label')\n",
    "    hemi_vertex=['hemi','vertex_index']\n",
    "    imorph_data=(imorph_data\n",
    "                 .sort_index(level=hemi_vertex)\n",
    "                 .unstack(hemi_vertex))\n",
    "    netpath=(\n",
    "        SUBJECTS_DIR+'/networks_ML/'+\n",
    "        meas+'_fwhm10_'+ netname+'fsaverage_df.pkl' \n",
    "    )\n",
    "    imorph_data.to_pickle(netpath)\n",
    "    print('Done with '+netname+' for '+meas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save individual network and wholebrain files\n",
    "for meas,imeas in meas_key.iteritems():\n",
    "    for netname,inet in net_key.iteritems():\n",
    "        write_morph_data(meas,imeas,netname,inet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add wholebrain average values to npdata\n",
    "\n",
    "- takes outputted wholebrain pickle files from above and\n",
    "averages (for thickness) or sums (for surface area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npdata_all.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npdata_all.query(\n",
    "    'subs in @morph_df_annot'\n",
    "    '.index.levels[3].values'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wb_area=pd.read_pickle(\n",
    "    '{}networks_ML/{}_fwhm{}_{}fsaverage_df.pkl'\n",
    "    .format(SUBJECTS_DIR,'area',str(10),'wholebrain'))\n",
    "wb_thick=pd.read_pickle(\n",
    "    '{}networks_ML/{}_fwhm{}_{}fsaverage_df.pkl'\n",
    "    .format(SUBJECTS_DIR,'thickness',str(10),'wholebrain'))\n",
    "wb_thick_avg=(wb_thick.mean(axis=1)\n",
    "              .reset_index(['measure'],drop=True)\n",
    "              .rename('wholebrain_thickness'))\n",
    "wb_area_avg=(wb_area.sum(axis=1)\n",
    "             .reset_index(['measure'],drop=True)\n",
    "             .rename('wholebrain_area'))\n",
    "wb_both=pd.concat([wb_thick_avg,wb_area_avg],axis=1)\n",
    "npdata=(npdata_all\n",
    "        .set_index(['subs'])\n",
    "        .join(wb_both,how='right'))\n",
    "npdata['Gender']=np.where(npdata['Gender']=='Female',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npdata.to_csv(datapath+'np_filter_wb_gendernum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
